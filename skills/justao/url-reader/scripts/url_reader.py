#!/usr/bin/env python3
"""
URL Reader - æ™ºèƒ½ç½‘é¡µå†…å®¹è¯»å–å™¨
ç­–ç•¥ï¼šFirecrawlï¼ˆé¦–é€‰ï¼‰â†’ Jinaï¼ˆå¤‡é€‰ï¼‰â†’ Playwrightï¼ˆå…œåº•ï¼‰
è‡ªåŠ¨ä¿å­˜å†…å®¹å’Œå›¾ç‰‡åˆ°æŒ‡å®šç›®å½•
"""

import os
import sys
import json
import asyncio
import requests
import re
import hashlib
from urllib.parse import urlparse
from pathlib import Path
from datetime import datetime

# é…ç½®
FIRECRAWL_API_KEY = os.environ.get("FIRECRAWL_API_KEY", "")
JINA_BASE_URL = "https://r.jina.ai/"
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent / "data"
WECHAT_AUTH_FILE = DATA_DIR / "wechat_auth.json"

# é»˜è®¤ä¿å­˜ç›®å½•
DEFAULT_OUTPUT_DIR = "/Users/ys/laoyangçŸ¥è¯†åº“/nickys/ç´ æ"


def identify_platform(url: str) -> dict:
    """è¯†åˆ«URLæ‰€å±å¹³å°"""
    parsed = urlparse(url)
    domain = parsed.netloc.lower()

    platforms = {
        'wechat': {
            'name': 'å¾®ä¿¡å…¬ä¼—å·',
            'domains': ['mp.weixin.qq.com'],
            'need_login': True
        },
        'xiaohongshu': {
            'name': 'å°çº¢ä¹¦',
            'domains': ['xiaohongshu.com', 'xhslink.com'],
            'need_login': False
        },
        'toutiao': {
            'name': 'ä»Šæ—¥å¤´æ¡',
            'domains': ['toutiao.com'],
            'need_login': False
        },
        'douyin': {
            'name': 'æŠ–éŸ³',
            'domains': ['douyin.com', 'v.douyin.com'],
            'need_login': False
        },
        'taobao': {
            'name': 'æ·˜å®',
            'domains': ['taobao.com', 'item.taobao.com'],
            'need_login': True
        },
        'tmall': {
            'name': 'å¤©çŒ«',
            'domains': ['tmall.com', 'detail.tmall.com'],
            'need_login': True
        },
        'jd': {
            'name': 'äº¬ä¸œ',
            'domains': ['jd.com', 'item.jd.com'],
            'need_login': False
        },
        'zhihu': {
            'name': 'çŸ¥ä¹',
            'domains': ['zhihu.com', 'zhuanlan.zhihu.com'],
            'need_login': False
        },
        'weibo': {
            'name': 'å¾®åš',
            'domains': ['weibo.com', 'm.weibo.cn'],
            'need_login': True
        },
        'bilibili': {
            'name': 'Bç«™',
            'domains': ['bilibili.com', 'b23.tv'],
            'need_login': False
        },
        'baidu': {
            'name': 'ç™¾åº¦',
            'domains': ['baidu.com', 'baijiahao.baidu.com'],
            'need_login': False
        },
    }

    for platform_id, info in platforms.items():
        for d in info['domains']:
            if d in domain:
                return {'id': platform_id, **info}

    return {
        'id': 'generic',
        'name': 'é€šç”¨ç½‘ç«™',
        'domains': [],
        'need_login': False
    }


def read_with_firecrawl(url: str) -> dict:
    """ç­–ç•¥Aï¼šä½¿ç”¨ Firecrawl API è¯»å–"""
    if not FIRECRAWL_API_KEY:
        return {'success': False, 'error': 'FIRECRAWL_API_KEY æœªè®¾ç½®'}

    try:
        from firecrawl import Firecrawl
        app = Firecrawl(api_key=FIRECRAWL_API_KEY)
        result = app.scrape(url)

        if result:
            # Firecrawl v2 è¿”å› Document å¯¹è±¡
            markdown = getattr(result, 'markdown', '') or ''
            metadata = getattr(result, 'metadata', None)
            if metadata:
                metadata = metadata.model_dump() if hasattr(metadata, 'model_dump') else {}
            else:
                metadata = {}

            if markdown and len(markdown) > 100:
                # æ£€æŸ¥æ˜¯å¦æ˜¯éªŒè¯é¡µé¢
                if 'ç¯å¢ƒå¼‚å¸¸' in markdown or 'éªŒè¯' in markdown[:200]:
                    return {'success': False, 'error': 'é¡µé¢éœ€è¦éªŒè¯'}

                return {
                    'success': True,
                    'strategy': 'Firecrawl',
                    'content': markdown,
                    'metadata': metadata
                }

        return {'success': False, 'error': 'Firecrawl è¿”å›å†…å®¹ä¸ºç©º'}

    except Exception as e:
        return {'success': False, 'error': f'Firecrawl é”™è¯¯: {str(e)}'}


def read_with_jina(url: str) -> dict:
    """ç­–ç•¥B-1ï¼šä½¿ç”¨ Jina Reader API è¯»å–ï¼ˆå…è´¹ï¼‰"""
    try:
        jina_url = f"{JINA_BASE_URL}{url}"
        headers = {
            'Accept': 'text/markdown',
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }

        response = requests.get(jina_url, headers=headers, timeout=30)

        if response.status_code == 200:
            content = response.text

            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ‰æ•ˆå†…å®¹
            if 'ç¯å¢ƒå¼‚å¸¸' in content or 'å®ŒæˆéªŒè¯' in content:
                return {'success': False, 'error': 'é¡µé¢éœ€è¦éªŒè¯'}

            if len(content) < 100:
                return {'success': False, 'error': 'å†…å®¹å¤ªçŸ­ï¼Œå¯èƒ½è¯»å–å¤±è´¥'}

            return {
                'success': True,
                'strategy': 'Jina Reader',
                'content': content,
                'metadata': {}
            }

        return {'success': False, 'error': f'HTTP {response.status_code}'}

    except Exception as e:
        return {'success': False, 'error': f'Jina é”™è¯¯: {str(e)}'}


async def read_with_playwright_async(url: str, platform_id: str) -> dict:
    """ç­–ç•¥B-2ï¼šä½¿ç”¨ Playwright æµè§ˆå™¨è¯»å–ï¼ˆéœ€è¦ç™»å½•æ€ï¼‰"""
    try:
        from playwright.async_api import async_playwright
        import time

        # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•æ€
        auth_file = None
        if platform_id == 'wechat' and WECHAT_AUTH_FILE.exists():
            auth_file = str(WECHAT_AUTH_FILE)

        async with async_playwright() as p:
            # ä½¿ç”¨ç§»åŠ¨ç«¯ User-Agent å¯èƒ½æ›´å®¹æ˜“é€šè¿‡éªŒè¯
            browser = await p.chromium.launch(headless=True)

            # ä½¿ç”¨å¾®ä¿¡å†…ç½®æµè§ˆå™¨çš„ User-Agent
            mobile_ua = 'Mozilla/5.0 (iPhone; CPU iPhone OS 16_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148 MicroMessenger/8.0.38(0x18002629) NetType/WIFI Language/zh_CN'

            if auth_file:
                context = await browser.new_context(
                    storage_state=auth_file,
                    user_agent=mobile_ua
                )
            else:
                context = await browser.new_context(
                    user_agent=mobile_ua
                )

            page = await context.new_page()

            await page.goto(url, wait_until="networkidle", timeout=30000)

            # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½
            await page.wait_for_timeout(2000)

            # æ£€æŸ¥æ˜¯å¦éœ€è¦éªŒè¯
            content = await page.content()
            if 'ç¯å¢ƒå¼‚å¸¸' in content or 'å®ŒæˆéªŒè¯' in content:
                # å°è¯•ç‚¹å‡»éªŒè¯æŒ‰é’®
                verify_btn = await page.query_selector("text=å»éªŒè¯")
                if verify_btn:
                    await verify_btn.click()
                    await page.wait_for_timeout(3000)
                    await page.wait_for_load_state("networkidle", timeout=15000)
                    content = await page.content()

                if 'ç¯å¢ƒå¼‚å¸¸' in content or 'å®ŒæˆéªŒè¯' in content:
                    await browser.close()
                    return {'success': False, 'error': 'éœ€è¦æ‰‹åŠ¨éªŒè¯ï¼Œè¯·è¿è¡Œ setup å‘½ä»¤ç™»å½•'}

            # ç­‰å¾…æ–‡ç« å†…å®¹åŠ è½½
            if platform_id == 'wechat':
                try:
                    await page.wait_for_selector('#js_content', timeout=10000)
                except:
                    pass

            # æå–å†…å®¹
            if platform_id == 'wechat':
                result = await page.evaluate("""
                    () => {
                        const title = document.querySelector('#activity-name')?.innerText?.trim() || '';
                        const author = document.querySelector('#js_name')?.innerText?.trim() || '';
                        const content = document.querySelector('#js_content')?.innerText?.trim() || '';
                        const publishTime = document.querySelector('#publish_time')?.innerText?.trim() || '';
                        return { title, author, content, publishTime };
                    }
                """)
            else:
                # é€šç”¨æå–
                result = await page.evaluate("""
                    () => {
                        const title = document.querySelector('h1')?.innerText?.trim() ||
                                     document.querySelector('title')?.innerText?.trim() || '';
                        const content = document.body.innerText || '';
                        return { title, author: '', content, publishTime: '' };
                    }
                """)

            await browser.close()

            if result.get('content') and len(result['content']) > 100:
                # æ ¼å¼åŒ–ä¸º Markdown
                markdown = f"# {result.get('title', 'æ— æ ‡é¢˜')}\n\n"
                if result.get('author'):
                    markdown += f"**ä½œè€…**: {result['author']}\n"
                if result.get('publishTime'):
                    markdown += f"**å‘å¸ƒæ—¶é—´**: {result['publishTime']}\n"
                markdown += f"\n---\n\n{result.get('content', '')}"

                return {
                    'success': True,
                    'strategy': 'Playwright',
                    'content': markdown,
                    'metadata': {
                        'title': result.get('title', ''),
                        'author': result.get('author', ''),
                        'publishTime': result.get('publishTime', '')
                    }
                }

            return {'success': False, 'error': 'é¡µé¢å†…å®¹æå–å¤±è´¥'}

    except Exception as e:
        return {'success': False, 'error': f'Playwright é”™è¯¯: {str(e)}'}


def read_with_playwright(url: str, platform_id: str) -> dict:
    """Playwright åŒæ­¥åŒ…è£…"""
    return asyncio.run(read_with_playwright_async(url, platform_id))


def read_url(url: str, verbose: bool = True) -> dict:
    """
    æ™ºèƒ½è¯»å–URLå†…å®¹
    ç­–ç•¥é¡ºåºï¼šFirecrawl â†’ Jina â†’ Playwright
    """
    # è¯†åˆ«å¹³å°
    platform = identify_platform(url)
    if verbose:
        print(f"ğŸ“ å¹³å°è¯†åˆ«: {platform['name']}")

    errors = []

    # ç­–ç•¥1: Firecrawlï¼ˆå¦‚æœæœ‰ API Keyï¼‰
    if FIRECRAWL_API_KEY:
        if verbose:
            print("ğŸ”„ å°è¯•ç­–ç•¥ A: Firecrawl...")
        result = read_with_firecrawl(url)
        if result.get('success'):
            if verbose:
                print("âœ… Firecrawl è¯»å–æˆåŠŸ")
            result['platform'] = platform
            return result
        errors.append(f"Firecrawl: {result.get('error')}")
        if verbose:
            print(f"âŒ {result.get('error')}")

    # ç­–ç•¥2: Jina Readerï¼ˆå…è´¹ï¼Œä¸éœ€è¦ç™»å½•çš„å¹³å°ä¼˜å…ˆå°è¯•ï¼‰
    if not platform.get('need_login'):
        if verbose:
            print("ğŸ”„ å°è¯•ç­–ç•¥ B-1: Jina Reader...")
        result = read_with_jina(url)
        if result.get('success'):
            if verbose:
                print("âœ… Jina Reader è¯»å–æˆåŠŸ")
            result['platform'] = platform
            return result
        errors.append(f"Jina: {result.get('error')}")
        if verbose:
            print(f"âŒ {result.get('error')}")

    # ç­–ç•¥3: Playwrightï¼ˆéœ€è¦ç™»å½•çš„å¹³å°æˆ–å‰é¢éƒ½å¤±è´¥ï¼‰
    if verbose:
        print("ğŸ”„ å°è¯•ç­–ç•¥ B-2: Playwright æµè§ˆå™¨...")
    result = read_with_playwright(url, platform['id'])
    if result.get('success'):
        if verbose:
            print("âœ… Playwright è¯»å–æˆåŠŸ")
        result['platform'] = platform
        return result
    errors.append(f"Playwright: {result.get('error')}")
    if verbose:
        print(f"âŒ {result.get('error')}")

    # å¦‚æœæ˜¯éœ€è¦ç™»å½•çš„å¹³å°ï¼ŒJina ä½œä¸ºæœ€åå°è¯•
    if platform.get('need_login'):
        if verbose:
            print("ğŸ”„ æœ€åå°è¯•: Jina Reader...")
        result = read_with_jina(url)
        if result.get('success'):
            if verbose:
                print("âœ… Jina Reader è¯»å–æˆåŠŸ")
            result['platform'] = platform
            return result
        errors.append(f"Jina (fallback): {result.get('error')}")

    return {
        'success': False,
        'platform': platform,
        'errors': errors
    }


def format_output(result: dict, url: str) -> str:
    """æ ¼å¼åŒ–è¾“å‡ºä¸º Markdown"""
    if not result.get('success'):
        output = ["# âŒ è¯»å–å¤±è´¥\n"]
        output.append(f"**URL**: {url}")
        output.append(f"**å¹³å°**: {result.get('platform', {}).get('name', 'æœªçŸ¥')}")
        output.append("\n**å°è¯•çš„ç­–ç•¥åŠé”™è¯¯**:")
        for err in result.get('errors', []):
            output.append(f"- {err}")
        output.append("\n**å»ºè®®**:")
        output.append("1. å¦‚æœæ˜¯å¾®ä¿¡å…¬ä¼—å·ï¼Œè¯·è¿è¡Œ `python wechat_reader.py setup` è®¾ç½®ç™»å½•æ€")
        output.append("2. è®¾ç½® FIRECRAWL_API_KEY ç¯å¢ƒå˜é‡ä»¥ä½¿ç”¨ Firecrawl")
        output.append("3. æˆ–æ‰‹åŠ¨å¤åˆ¶æ–‡ç« å†…å®¹")
        return "\n".join(output)

    platform = result.get('platform', {})
    metadata = result.get('metadata', {})
    content = result.get('content', '')

    output = []
    output.append(f"**æ¥æº**: {platform.get('name', 'æœªçŸ¥')}")
    output.append(f"**è¯»å–ç­–ç•¥**: {result.get('strategy', 'æœªçŸ¥')}")
    output.append(f"**åŸæ–‡é“¾æ¥**: {url}")
    output.append("\n---\n")
    output.append(content)

    return "\n".join(output)


# ============== ä¿å­˜åŠŸèƒ½ ==============

def sanitize_filename(name: str, max_length: int = 50) -> str:
    """æ¸…ç†æ–‡ä»¶åï¼Œç§»é™¤éæ³•å­—ç¬¦"""
    name = re.sub(r'[<>:"/\\|?*\n\r\t]', '', name)
    name = re.sub(r'\s+', ' ', name).strip()
    if len(name) > max_length:
        name = name[:max_length]
    return name or "untitled"


def extract_title_from_content(content: str) -> str:
    """ä»å†…å®¹ä¸­æå–æ ‡é¢˜"""
    # å°è¯•ä» Markdown ä¸€çº§æ ‡é¢˜æå–
    match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
    if match:
        title = match.group(1).strip()
        # æ’é™¤ä¸€äº›æ— æ„ä¹‰çš„æ ‡é¢˜
        if title and not title.startswith('æ¥æº') and not title.startswith('**') and len(title) > 2:
            return title

    # å°è¯•ä» **æ ‡é¢˜**: æ ¼å¼æå–
    match = re.search(r'\*\*æ ‡é¢˜\*\*[ï¼š:]\s*(.+)', content)
    if match:
        return match.group(1).strip()

    # å°è¯•ä»ç¬¬ä¸€ä¸ªæœ‰æ„ä¹‰çš„è¡Œæå–
    lines = content.strip().split('\n')
    for line in lines:
        line = line.strip()
        # è·³è¿‡ç©ºè¡Œã€å…ƒæ•°æ®è¡Œ
        if not line or line.startswith('**') or line.startswith('---') or line.startswith('#'):
            continue
        if len(line) > 5 and len(line) < 100:
            return line[:50]

    return "untitled"


def extract_images_from_content(content: str) -> list:
    """ä»å†…å®¹ä¸­æå–å›¾ç‰‡URL"""
    md_images = re.findall(r'!\[.*?\]\((https?://[^\s\)]+)\)', content)
    direct_images = re.findall(r'(https?://[^\s\)]+\.(?:jpg|jpeg|png|gif|webp|bmp)[^\s\)]*)', content, re.IGNORECASE)
    xhs_images = re.findall(r'(https?://sns-webpic[^\s\)]+)', content)
    feishu_images = re.findall(r'(https?://[^\s\)]*feishu[^\s\)]+\.(?:jpg|jpeg|png|gif|webp)[^\s\)]*)', content, re.IGNORECASE)
    qq_images = re.findall(r'(https?://docimg[^\s\)]+\.(?:jpg|jpeg|png|gif|webp)[^\s\)]*)', content, re.IGNORECASE)
    all_images = list(dict.fromkeys(md_images + direct_images + xhs_images + feishu_images + qq_images))
    return all_images


def download_image(url: str, save_dir: Path, index: int) -> str:
    """ä¸‹è½½å›¾ç‰‡å¹¶è¿”å›æœ¬åœ°æ–‡ä»¶å"""
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36',
            'Referer': 'https://www.xiaohongshu.com/'
        }
        response = requests.get(url, headers=headers, timeout=30)
        response.raise_for_status()

        content_type = response.headers.get('content-type', '')
        if 'webp' in content_type or 'webp' in url:
            ext = '.webp'
        elif 'png' in content_type or 'png' in url:
            ext = '.png'
        elif 'gif' in content_type or 'gif' in url:
            ext = '.gif'
        else:
            ext = '.jpg'

        filename = f"img_{index:02d}{ext}"
        filepath = save_dir / filename

        with open(filepath, 'wb') as f:
            f.write(response.content)

        return filename
    except Exception as e:
        return None


def save_content(content: str, url: str, platform_name: str = "", output_dir: str = None, title: str = None, verbose: bool = True) -> dict:
    """
    ä¿å­˜å†…å®¹åˆ°æœ¬åœ°
    """
    output_dir = Path(output_dir or DEFAULT_OUTPUT_DIR)
    output_dir.mkdir(parents=True, exist_ok=True)

    if not title:
        title = extract_title_from_content(content)

    date_str = datetime.now().strftime("%Y-%m-%d")
    folder_name = f"{date_str}_{sanitize_filename(title)}"

    content_dir = output_dir / folder_name
    content_dir.mkdir(parents=True, exist_ok=True)

    images = extract_images_from_content(content)
    image_mapping = {}

    if images and verbose:
        print(f"ğŸ“· å‘ç° {len(images)} å¼ å›¾ç‰‡ï¼Œæ­£åœ¨ä¸‹è½½...")

    for i, img_url in enumerate(images, 1):
        local_name = download_image(img_url, content_dir, i)
        if local_name:
            image_mapping[img_url] = local_name
            if verbose:
                print(f"  âœ“ {local_name}")

    updated_content = content
    for orig_url, local_name in image_mapping.items():
        updated_content = updated_content.replace(orig_url, local_name)

    meta = f"""---
title: {title}
platform: {platform_name}
url: {url}
saved_at: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
images: {len(image_mapping)}
---

"""

    md_path = content_dir / "content.md"
    with open(md_path, 'w', encoding='utf-8') as f:
        f.write(meta + updated_content)

    if verbose:
        print(f"\nğŸ’¾ å·²ä¿å­˜åˆ°: {content_dir}")
        print(f"   - content.md")
        print(f"   - å›¾ç‰‡: {len(image_mapping)} å¼ ")

    return {
        'success': True,
        'dir': str(content_dir),
        'md_file': str(md_path),
        'images': len(image_mapping),
        'title': title
    }


def read_and_save(url: str, output_dir: str = None, verbose: bool = True) -> dict:
    """
    è¯»å–URLå†…å®¹å¹¶ä¿å­˜åˆ°æœ¬åœ°
    """
    result = read_url(url, verbose=verbose)

    if not result.get('success'):
        return result

    platform = result.get('platform', {})
    content = format_output(result, url)

    save_result = save_content(
        content=content,
        url=url,
        platform_name=platform.get('name', 'æœªçŸ¥'),
        output_dir=output_dir,
        verbose=verbose
    )

    result['save'] = save_result
    return result


def main():
    if len(sys.argv) < 2:
        print("=" * 60)
        print("URL Reader - æ™ºèƒ½ç½‘é¡µå†…å®¹è¯»å–å™¨")
        print("=" * 60)
        print("\nç”¨æ³•:")
        print("  python url_reader.py <url>              # è¯»å–å¹¶æ˜¾ç¤º")
        print("  python url_reader.py <url> --save       # è¯»å–å¹¶ä¿å­˜")
        print("\nç¤ºä¾‹:")
        print("  python url_reader.py https://mp.weixin.qq.com/s/xxxxx --save")
        print("\nä¿å­˜ç›®å½•:")
        print(f"  {DEFAULT_OUTPUT_DIR}")
        print("\nç­–ç•¥ä¼˜å…ˆçº§:")
        print("  1. Firecrawl (éœ€è¦ API Key)")
        print("  2. Jina Reader (å…è´¹)")
        print("  3. Playwright (éœ€è¦ç™»å½•æ€)")
        print("\nç¯å¢ƒå˜é‡:")
        print(f"  FIRECRAWL_API_KEY: {'å·²è®¾ç½®' if FIRECRAWL_API_KEY else 'æœªè®¾ç½®'}")
        print(f"  å¾®ä¿¡ç™»å½•æ€: {'å·²è®¾ç½®' if WECHAT_AUTH_FILE.exists() else 'æœªè®¾ç½®'}")
        return

    url = sys.argv[1]
    save_mode = '--save' in sys.argv

    print(f"\n{'=' * 60}")
    print(f"æ­£åœ¨è¯»å–: {url}")
    print(f"{'=' * 60}\n")

    if save_mode:
        result = read_and_save(url)
        if result.get('success') and result.get('save'):
            print(f"\n{'=' * 60}")
            print("âœ… è¯»å–å¹¶ä¿å­˜æˆåŠŸ")
            print(f"{'=' * 60}")
    else:
        result = read_url(url)
        output = format_output(result, url)
        print(f"\n{'=' * 60}")
        print("è¯»å–ç»“æœ")
        print(f"{'=' * 60}\n")
        print(output)


if __name__ == "__main__":
    main()
